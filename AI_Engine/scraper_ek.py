from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from webdriver_manager.chrome import ChromeDriverManager
from selenium.webdriver.common.by import By
from selenium.webdriver.chrome.options import Options
import pandas as pd
import time
import random
import os

# --- DÃœZELTÄ°LMÄ°Å VE KONTROL EDÄ°LMÄ°Å LÄ°NKLER ---
CATEGORIES_TO_ADD = {
    # Televizyon iÃ§in 'elektronik' Ã¶n eki kaldÄ±rÄ±ldÄ±
    "Televizyon": "https://www.n11.com/televizyon-ve-ses-sistemleri/televizyon",
    
    # AkÄ±llÄ± Saat iÃ§in 'giyilebilir-teknoloji' ara kategorisi eklendi
    "AkilliSaat": "https://www.n11.com/telefon-ve-aksesuarlari/giyilebilir-teknoloji/akilli-saat",
    
    # Oyun Konsolu (Ã‡alÄ±ÅŸtÄ±ÄŸÄ± iÃ§in aynÄ± bÄ±rakÄ±ldÄ±)
    "OyunKonsolu": "https://www.n11.com/video-oyun-konsol",
    
    # KulaklÄ±k iÃ§in en popÃ¼ler ve dolu kategori olan 'Bluetooth KulaklÄ±k' seÃ§ildi
    "Kulaklik": "https://www.n11.com/telefon-ve-aksesuarlari/cep-telefonu-aksesuarlari/bluetooth-kulaklik",
    
    # YazÄ±cÄ± iÃ§in kategori ismi 'yazici-tarayici-ve-aksesuarlari' olarak gÃ¼ncellendi
    "Yazici": "https://www.n11.com/bilgisayar/yazici-tarayici-ve-aksesuarlari/yazici",
    
}

MAX_PAGES = 30 
DELAY = 2

def setup_driver():
    chrome_options = Options()
    chrome_options.add_argument("--disable-blink-features=AutomationControlled")
    chrome_options.add_argument("user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36")
    chrome_options.add_argument("--start-maximized")
    
    service = Service(ChromeDriverManager().install())
    driver = webdriver.Chrome(service=service, options=chrome_options)
    return driver

def scrape_missing_data():
    driver = setup_driver()
    new_products = []
    
    print(f"ğŸš€ EKSÄ°K VERÄ° AVI BAÅLIYOR... (Hedef: {list(CATEGORIES_TO_ADD.keys())})")

    for cat_name, cat_url in CATEGORIES_TO_ADD.items():
        print(f"\nğŸ“‚ EK KATEGORÄ°: {cat_name} taranÄ±yor...")
        
        for page in range(1, MAX_PAGES + 1):
            current_url = f"{cat_url}?pg={page}"
            try:
                driver.get(current_url)
                driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
                time.sleep(DELAY + random.random()) 
                
                cards = driver.find_elements(By.CSS_SELECTOR, "li.column")
                
                if len(cards) == 0:
                    print(f"   âš ï¸ Sayfa {page} boÅŸ veya yÃ¼klenmedi, geÃ§iliyor.")
                    continue 

                print(f"   â”œâ”€â”€ Sayfa {page}: {len(cards)} Ã¼rÃ¼n bulundu.")

                for card in cards:
                    try:
                        title = card.find_element(By.CLASS_NAME, "productName").text
                        try:
                            price_element = card.find_element(By.CSS_SELECTOR, ".newPrice ins")
                            price = price_element.text.strip()
                        except: price = "0"

                        try: link = card.find_element(By.TAG_NAME, "a").get_attribute("href")
                        except: link = ""
                        
                        brand = title.split(" ")[0]
                        
                        try:
                            rating_text = card.find_element(By.CLASS_NAME, "ratingText").text
                            rating_count = rating_text.replace("(", "").replace(")", "")
                        except: rating_count = "0"

                        if price != "0":
                            new_products.append({
                                "Kategori": cat_name,
                                "Marka": brand,
                                "Model": title,
                                "Fiyat": price,
                                "Yorum_Sayisi": rating_count,
                                "Link": link
                            })
                    except: continue
            except Exception as e:
                print(f"âš ï¸ Hata: {e}")
                continue

    driver.quit()
    return new_products

if __name__ == "__main__":
    # 1. Mevcut DosyayÄ± Oku
    EXISTING_FILE = "tum_urunler.csv" 
    
    if os.path.exists(EXISTING_FILE):
        print(f"ğŸ“‚ Mevcut dosya '{EXISTING_FILE}' okunuyor...")
        try:
            df_old = pd.read_csv(EXISTING_FILE)
            print(f"   -> Mevcut KayÄ±t SayÄ±sÄ±: {len(df_old)}")
        except:
            df_old = pd.DataFrame()
    else:
        print("âš ï¸ Mevcut dosya bulunamadÄ±, sÄ±fÄ±rdan baÅŸlanÄ±yor.")
        df_old = pd.DataFrame()

    # 2. Yeni Verileri Ã‡ek
    new_data = scrape_missing_data()
    
    if len(new_data) > 0:
        df_new = pd.DataFrame(new_data)
        
        # 3. BirleÅŸtir
        df_final = pd.concat([df_old, df_new], ignore_index=True)
        
        # 4. Temizlik
        print("ğŸ§¹ Veriler birleÅŸtiriliyor ve kopyalar siliniyor...")
        before_dedup = len(df_final)
        df_final.drop_duplicates(subset=['Link'], keep='first', inplace=True)
        
        # Fiyat TemizliÄŸi
        try:
            df_final['Fiyat'] = df_final['Fiyat'].astype(str).str.replace(" TL", "").str.replace("TL", "")
            df_final['Fiyat'] = df_final['Fiyat'].str.replace(".", "").str.replace(",", ".")
        except: pass

        # 5. Kaydet
        FINAL_FILE = "tum_urunler_final.csv" 
        df_final.to_csv(FINAL_FILE, index=False)
        
        print("\n" + "="*50)
        print(f"âœ… Ä°ÅLEM TAMAMLANDI!")
        print(f"   - Eski Veri: {len(df_old)}")
        print(f"   - Yeni Ã‡ekilen: {len(df_new)}")
        print(f"   - BirleÅŸim SonrasÄ± (Toplam): {before_dedup}")
        print(f"   - Kopyalar Silindikten Sonra (Net): {len(df_final)}")
        print(f"   - Dosya: {FINAL_FILE}")
        print("="*50)
        print(df_final.groupby("Kategori").count())
    else:
        print("âŒ Yeni veri Ã§ekilemedi. Linkleri veya internet baÄŸlantÄ±nÄ±zÄ± kontrol edin.")